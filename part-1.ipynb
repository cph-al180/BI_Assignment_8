{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# 1.1\n",
    "# Accuracy is how close a measured value is to the actual (true) value\n",
    "# Precision is how close the measured values are to each other\n",
    "\n",
    "# 1.2\n",
    "# precision is the fraction of retrieved documents that are relevant to the query\n",
    "# For example, for a text search on a set of documents, \n",
    "# precision is the number of correct results divided by the number of all returned results\n",
    "\n",
    "# recall is the fraction of the relevant documents that are successfully retrieved\n",
    "# For example, for a text search on a set of documents, \n",
    "# recall is the number of correct results divided by the number of results that should have been returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.model_selection import KFold, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Mean radius</th>\n",
       "      <th>Mean texture</th>\n",
       "      <th>Mean perimeter</th>\n",
       "      <th>Mean area</th>\n",
       "      <th>Mean smoothness</th>\n",
       "      <th>Mean compactness</th>\n",
       "      <th>Mean concavity</th>\n",
       "      <th>Mean concave points</th>\n",
       "      <th>...</th>\n",
       "      <th>Worst radius</th>\n",
       "      <th>Worst texture</th>\n",
       "      <th>Worst perimeter</th>\n",
       "      <th>Worst area</th>\n",
       "      <th>Worst smoothness</th>\n",
       "      <th>Worst compactness</th>\n",
       "      <th>Worst concavity</th>\n",
       "      <th>Worst concave points</th>\n",
       "      <th>Worst symmetry</th>\n",
       "      <th>Worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Diagnosis  Mean radius  Mean texture  Mean perimeter  Mean area  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   Mean smoothness  Mean compactness  Mean concavity  Mean concave points  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "            ...             Worst radius  Worst texture  Worst perimeter  \\\n",
       "0           ...                    25.38          17.33           184.60   \n",
       "1           ...                    24.99          23.41           158.80   \n",
       "2           ...                    23.57          25.53           152.50   \n",
       "3           ...                    14.91          26.50            98.87   \n",
       "4           ...                    22.54          16.67           152.20   \n",
       "\n",
       "   Worst area  Worst smoothness  Worst compactness  Worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   Worst concave points  Worst symmetry  Worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('BreastCancer.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracies:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.62      0.45      0.53        11\n",
      "  Malignant       0.88      0.93      0.91        46\n",
      "\n",
      "avg / total       0.83      0.84      0.83        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.92      0.94      0.93        35\n",
      "  Malignant       0.90      0.86      0.88        22\n",
      "\n",
      "avg / total       0.91      0.91      0.91        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.87      0.94      0.91        36\n",
      "  Malignant       0.89      0.76      0.82        21\n",
      "\n",
      "avg / total       0.88      0.88      0.87        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.93      0.90      0.91        29\n",
      "  Malignant       0.90      0.93      0.91        28\n",
      "\n",
      "avg / total       0.91      0.91      0.91        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.93      0.93      0.93        29\n",
      "  Malignant       0.93      0.93      0.93        28\n",
      "\n",
      "avg / total       0.93      0.93      0.93        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.96      1.00      0.98        45\n",
      "  Malignant       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.97      0.96      0.96        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.91      0.95      0.93        41\n",
      "  Malignant       0.86      0.75      0.80        16\n",
      "\n",
      "avg / total       0.89      0.89      0.89        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.95      0.95      0.95        44\n",
      "  Malignant       0.85      0.85      0.85        13\n",
      "\n",
      "avg / total       0.93      0.93      0.93        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.91      0.95      0.93        44\n",
      "  Malignant       0.82      0.69      0.75        13\n",
      "\n",
      "avg / total       0.89      0.89      0.89        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.98      0.98      0.98        43\n",
      "  Malignant       0.92      0.92      0.92        13\n",
      "\n",
      "avg / total       0.96      0.96      0.96        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic = linear_model.LogisticRegression()\n",
    "variables = ['Mean radius','Mean texture','Mean perimeter','Mean area','Mean smoothness','Mean compactness','Mean symmetry']\n",
    "\n",
    "x = df[variables].values.reshape(-1,len(variables))\n",
    "y = df['Diagnosis']\n",
    "\n",
    "folds = KFold(n_splits=10)\n",
    "\n",
    "accuracies = []\n",
    "    \n",
    "print()\n",
    "print(\"accuracies:\")\n",
    "\n",
    "for train_indices, test_indices in folds.split(x, y):\n",
    "    x_train, x_test = x[train_indices], x[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    logreg.fit(x_train, y_train)\n",
    "\n",
    "    prediction = cross_val_predict(logistic,x_test,y_test, cv=10)\n",
    "\n",
    "    accuracy = metrics.classification_report(y_test, prediction, target_names=[\"Benign\",\"Malignant\"])\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# most of our guesses lay around a score of 0.9\n",
    "# which means we are very consistent with guessing right\n",
    "# but our support is'nt that great, so to be more secure in our guesses\n",
    "# we need a bigger data sample. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
